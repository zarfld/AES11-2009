name: CI - Standards Compliance & Quality Gates

on:
  push:
    branches: [main, master, develop, "feature/**", "release/**"]
  pull_request:
    branches: [main, master, develop]
  schedule:
    # Run weekly at 2 AM UTC (Sunday)
    - cron: "0 2 * * 0"

env:
  NODE_VERSION: "20.x"
  PYTHON_VERSION: "3.11"
  MIN_TEST_COVERAGE: 80
  MAX_CYCLOMATIC_COMPLEXITY: 10
  # Strict linkage targets (authentic, manually authored links only)
  MIN_REQ_LINKAGE_COVERAGE: 90

permissions:
  contents: read
  security-events: write

jobs:
  spec-validation:
    name: Spec Structure Validation (Schema & Traceability Prereq)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install dependencies
        run: pip install pyyaml jsonschema
      - name: Validate spec structure
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/validate-spec-structure.py || {
            echo 'âŒ Spec structure validation failed.'
            exit 1
          }
  spec-generation:
    needs: [spec-validation]
    name: Spec Artifact Generation (Index, Trace JSON, Test Skeletons)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Generate spec index
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/generators/spec_parser.py
      - name: Build traceability JSON
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/generators/build_trace_json.py
      - name: Generate requirement test skeletons
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/generators/gen_tests.py
      - name: Upload generated artifacts
        uses: actions/upload-artifact@v4
        with:
          name: spec-generated-artifacts
          path: |
            build/spec-index.json
            build/traceability.json
            05-implementation/tests/generated/
  # Phase 05: Implementation Quality Checks
  code-quality:
    needs: [spec-generation]
    name: C/C++ Code Quality & Standards (IEEE 1016, XP Practices)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Full history for better analysis

      - name: Phase 05 Traceability Header Enforcement
        run: |
          echo "ðŸ”Ž Enforcing Phase 05 traceability headers before quality checks..."
          python3 scripts/ci/check-traceability-headers.py

      - name: Phase 05 Test Headers & Naming Enforcement
        run: |
          echo "ðŸ”Ž Enforcing Phase 05 test header and naming conventions..."
          python3 scripts/ci/check-test-headers-and-naming.py

      - name: Install C/C++ quality tools
        run: |
          sudo apt-get update
          sudo apt-get install -y clang-format cppcheck clang-tidy python3-pip
          pip3 install --user lizard mdformat pyyaml

      - name: Check C/C++ formatting (clang-format)
        # Non-blocking: pipeline continues even if formatting differences exist.
        # Rationale: allows downstream build/tests to run to surface functional issues.
        # Trade-off: formatting violations become advisory; enforcement shifts to review or separate gating.
        continue-on-error: true
        run: |
          echo "ðŸ“ Checking C/C++ formatting with clang-format..."
          FILES=$(git ls-files "*.c" "*.cc" "*.cpp" "*.cxx" "*.h" "*.hh" "*.hpp" "*.hxx")
          if [ -n "$FILES" ]; then
            clang-format -version
            # Enforce repository style; ensure .clang-format is honored
            if ! clang-format -n --Werror -style=file $FILES; then
              echo "âš ï¸ Formatting differences detected. Showing unified diffs (proposed by clang-format):"
              for f in $FILES; do
                # Print diff between current file and clang-format output
                clang-format -style=file "$f" | diff -u "$f" - || true
              done
              echo "Formatting check failed (non-blocking)."
            fi
          else
            echo "No C/C++ files to format-check"
          fi
      - name: Persist formatting diff summary (if any)
        if: always()
        run: |
          echo "Capturing formatting diff summary (non-blocking)..."
          FILES=$(git ls-files "*.c" "*.cc" "*.cpp" "*.cxx" "*.h" "*.hh" "*.hpp" "*.hxx")
          if [ -n "$FILES" ]; then
            SUMMARY_FILE=build/format-diff-summary.txt
            mkdir -p build
            > $SUMMARY_FILE
            for f in $FILES; do
              DIFF=$(clang-format -style=file "$f" | diff -u "$f" - || true)
              if [ -n "$DIFF" ]; then
                printf "===== %s =====\n" "$f" >> $SUMMARY_FILE
                printf "%s\n\n" "$DIFF" >> $SUMMARY_FILE
              fi
            done
            if [ -s $SUMMARY_FILE ]; then
              echo "Formatting differences captured in $SUMMARY_FILE"
            else
              echo "No formatting differences found" >> $SUMMARY_FILE
            fi
          fi
      - name: Upload formatting diff summary artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: formatting-diff-summary
          path: build/format-diff-summary.txt

      - name: Static analysis (cppcheck)
        run: |
          echo "ðŸ” Running cppcheck static analysis..."
          cppcheck --version
          cppcheck --enable=warning,style,performance,portability --inline-suppr --error-exitcode=1 \
            --suppress=missingIncludeSystem \
            lib tests || {
              echo "âŒ cppcheck found issues"; exit 1; }

      - name: Static analysis (clang-tidy)
        run: |
          echo "ðŸ” Running clang-tidy static analysis..."
          cmake -S . -B build -DBUILD_TESTS=ON -DCMAKE_EXPORT_COMPILE_COMMANDS=ON
          FILES=$(git ls-files "lib/**/*.c" "lib/**/*.cc" "lib/**/*.cpp" "lib/**/*.cxx" "lib/**/*.h" "lib/**/*.hh" "lib/**/*.hpp" "lib/**/*.hxx")
          if [ -n "$FILES" ]; then
            clang-tidy -p build --quiet $FILES || { echo "âŒ clang-tidy detected issues"; exit 1; }
          else
            echo "No C/C++ files for clang-tidy"
          fi

      - name: Quality metrics enforcement (complexity/length/params/duplication)
        run: |
          echo "ðŸ“Š Enforcing quality metrics with lizard (complexity, length, parameters, duplication)..."
          python3 scripts/ci/check-code-quality.py --config quality-gates.yml --out build/quality-metrics.json || {
            echo "âŒ Quality metrics threshold breached"; exit 1; }

      - name: Upload quality metrics artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-metrics
          path: |
            build/quality-metrics.json
            build/duplication-report.txt

      - name: Check Markdown formatting (mdformat)
        run: |
          echo "ðŸ“„ Validating Markdown formatting with mdformat (non-blocking)..."
          ~/.local/bin/mdformat --version
          ~/.local/bin/mdformat --check . || echo "âš ï¸ Markdown formatting differences detected"
      - name: Defect Discovery Rate (DDR) computation
        run: |
          echo "ðŸ§® Computing Defect Discovery Rate (DDR)..."
          pip3 install --user pyyaml >/dev/null 2>&1 || true
          DDR_MAX=5 python3 scripts/ci/compute-ddr.py || { echo "âŒ DDR threshold exceeded"; exit 1; }
      - name: Upload defect metrics artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: defect-metrics
          path: build/defect-metrics.json

  # Phase 05: TDD - Test-Driven Development
  cxx-implementation:
    name: C++ Standards Layer Build & Tests (Phase 05 TDD)
    runs-on: ubuntu-latest
    needs: [spec-generation]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install build tools
        if: ${{ hashFiles('CMakeLists.txt') != '' }}
        run: sudo apt-get update && sudo apt-get install -y build-essential cmake
      - name: Configure (CMake)
        if: ${{ hashFiles('CMakeLists.txt') != '' }}
        run: cmake -S . -B build -DBUILD_TESTS=ON
      - name: Build
        if: ${{ hashFiles('CMakeLists.txt') != '' }}
        run: cmake --build build -- -j$(nproc)
      - name: Run C++ tests
        if: ${{ hashFiles('CMakeLists.txt') != '' }}
        run: ctest --test-dir build --output-on-failure || { echo "âŒ C++ tests failed"; exit 1; }
      - name: Upload C++ test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cxx-test-results
          path: build/Testing
  unit-tests:
    name: Unit Tests (XP - TDD Red-Green-Refactor)
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        cxx_standard: [17]
        c_standard: [11]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Linux toolchain
      - name: Install build tools (Linux)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential cmake ninja-build

      # macOS toolchain
      - name: Install build tools (macOS)
        if: runner.os == 'macOS'
        run: |
          brew update
          brew install ninja cmake || true

      # Windows toolchain
      - name: Install build tools (Windows)
        if: runner.os == 'Windows'
        run: |
          choco install ninja -y --no-progress

      - name: Configure (CMake + Ninja)
        run: |
          cmake -S . -B build -G Ninja -DBUILD_TESTS=ON -DCMAKE_BUILD_TYPE=Release

      - name: Build
        run: |
          cmake --build build -- -k 0

      - name: Run unit tests
        run: |
          ctest --test-dir build --output-on-failure

      - name: Upload C++ test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-test-results-${{ matrix.os }}
          path: build/Testing

  traceability-coverage:
    name: Traceability Coverage Enforcement
    needs: [spec-generation]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Download traceability artifact
        uses: actions/download-artifact@v4
        with:
          name: spec-generated-artifacts
          # Download to repo root so the artifact's internal paths (build/traceability.json)
          # land at the expected location used by scripts (ROOT/build/traceability.json).
          path: .
      - name: List downloaded files (debug)
        run: |
          echo "Downloaded artifact contents:"
          ls -la
          echo "Build directory contents:"
          ls -la build || true
      - name: Enforce requirement linkage coverage
        run: |
          # Enforce overall requirement linkage now; relax others until scenarios are modeled
          ALLOW_EMPTY_SPECS=1 python scripts/validate-trace-coverage.py \
            --min-req ${{ env.MIN_REQ_LINKAGE_COVERAGE }} \
            --min-req-adr 70 \
            --min-req-scenario 60 \
            --min-req-test 40

  integrity-scan:
    name: Integrity Level Scan
    needs: [spec-generation]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Run integrity scan
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/integrity_level_scan.py
      - name: Upload integrity scan artifact
        uses: actions/upload-artifact@v4
        with:
          name: integrity-scan
          path: build/integrity-scan.json

  # Phase 06: Integration Testing
  integration-tests:
    name: Integration Tests (XP - Continuous Integration)
    runs-on: ubuntu-latest
    needs: [unit-tests]

    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        if: ${{ hashFiles('package.json') != '' }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: Install dependencies
        if: ${{ hashFiles('package.json') != '' }}
        run: npm ci

      - name: Run database migrations
        if: ${{ hashFiles('package.json') != '' }}
        run: |
          echo "ðŸ—„ï¸ Running database migrations..."
          npm run db:migrate
        env:
          DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db

      - name: Run integration tests
        if: ${{ hashFiles('package.json') != '' }}
        run: |
          echo "ðŸ”— Running integration tests..."
          npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379

      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: test-results/integration/

  # Phase 02: Requirements Traceability Check
  requirements-traceability:
    needs: [spec-validation]
    name: Requirements Traceability (ISO/IEC/IEEE 29148)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install traceability tools
        run: |
          pip install pyyaml markdown

      - name: Generate traceability matrix
        run: |
          echo "ðŸ” Generating requirements traceability matrix..."
          ALLOW_EMPTY_SPECS=1 python scripts/generate-traceability-matrix.py

      - name: Validate traceability
        run: |
          echo "âœ… Checking traceability completeness..."
          ALLOW_EMPTY_SPECS=1 python scripts/validate-traceability.py || {
            echo "âŒ Traceability validation failed"
            echo "Every requirement must trace to:"
            echo "  - Stakeholder requirement (StR-XXX)"
            echo "  - System requirement (REQ-XXX)"
            echo "  - Design element (DES-XXX)"
            echo "  - Implementation (CODE)"
            echo "  - Test case (TEST-XXX)"
            exit 1
          }

      - name: Upload traceability report
        uses: actions/upload-artifact@v4
        with:
          name: traceability-matrix
          path: reports/traceability-matrix.md

  # Phase 07: Verification & Validation (IEEE 1012)
  acceptance-tests:
    name: Acceptance Tests (XP - Customer Tests, IEEE 1012)
    runs-on: ubuntu-latest
    needs: [integration-tests]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        if: ${{ hashFiles('package.json') != '' }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: "npm"

      - name: Install dependencies
        if: ${{ hashFiles('package.json') != '' }}
        run: npm ci

      - name: Install Playwright
        if: ${{ hashFiles('package.json') != '' }}
        run: npx playwright install --with-deps

      - name: Build application
        if: ${{ hashFiles('package.json') != '' }}
        run: npm run build

      - name: Start application
        if: ${{ hashFiles('package.json') != '' }}
        run: |
          npm run start &
          echo $! > .app.pid
          # Wait for app to start
          npx wait-on http://localhost:3000 -t 60000

      - name: Run acceptance tests (BDD)
        if: ${{ hashFiles('package.json') != '' }}
        run: |
          echo "ðŸŽ­ Running acceptance tests (Behavior-Driven Development)..."
          npm run test:acceptance

      - name: Stop application
        if: always()
        run: |
          kill $(cat .app.pid) || true

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: acceptance-test-results
          path: |
            test-results/acceptance/
            playwright-report/

  # Phase 07: Verification & Validation (IEEE 1012)

  # Phase 03: Architecture Compliance (ISO/IEC/IEEE 42010)
  architecture-validation:
    needs: [spec-validation]
    name: Architecture Compliance (ISO/IEC/IEEE 42010)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: ADR Impact Scan
        run: |
          ALLOW_EMPTY_SPECS=1 python scripts/adr_impact_scan.py --warn-only || echo "ADR impact scan completed"

      - name: Validate Architecture Decision Records
        run: |
          echo "ðŸ“ Validating ADR completeness..."
          for adr in 03-architecture/decisions/*.md; do
            [ -f "$adr" ] || continue
            echo "Checking $adr..."
            grep -q "## Status" "$adr" || { echo "âŒ Missing Status section in $adr"; exit 1; }
            grep -q "## Context" "$adr" || { echo "âŒ Missing Context section in $adr"; exit 1; }
            grep -q "## Decision" "$adr" || { echo "âŒ Missing Decision section in $adr"; exit 1; }
            grep -q "## Consequences" "$adr" || { echo "âŒ Missing Consequences section in $adr"; exit 1; }
          done
      - name: Validate architecture views
        run: |
          echo "ðŸ—ï¸ Checking required architecture views..."
          REQUIRED_VIEWS=(logical process development physical data)
          for view in "${REQUIRED_VIEWS[@]}"; do
            if [ ! -d "03-architecture/views/$view" ]; then
              echo "âš ï¸ Missing architecture view: $view"
            fi
          done
      - name: Verify quality attribute scenarios
        run: |
          echo "ðŸ”Ž Checking quality attribute scenarios coverage..."
          FILE=03-architecture/architecture-quality-scenarios.md
          if [ ! -f "$FILE" ]; then
            echo "âŒ Missing quality attribute scenarios file"; exit 1; fi
          for attr in Performance Availability Security; do
            grep -qi "$attr" "$FILE" || { echo "âŒ Missing scenario for $attr"; exit 1; }
          done
          echo "âœ… Basic QA scenario coverage present"

  # Security Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run npm audit
        if: ${{ hashFiles('package.json') != '' }}
        run: |
          echo "ðŸ”’ Running npm security audit..."
          npm audit --audit-level=moderate

      - name: Run Snyk security scan
        run: |
          echo "âš ï¸ Snyk scan skipped (token not configured in lint environment)."

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@0.21.0
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "sarif"
          output: "trivy-results.sarif"
          ignore-unfixed: true
          severity: HIGH,CRITICAL
          exit-code: "0"

      - name: Upload Trivy results to GitHub Security
        uses: github/codeql-action/upload-sarif@v3
        # Upload only when not from a fork and when we have permissions to write security events
        if: ${{ always() && github.event.pull_request.head.repo.full_name == github.repository }}
        with:
          sarif_file: "trivy-results.sarif"
      - name: Preserve Trivy SARIF as artifact (fork PRs)
        if: ${{ always() && github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name != github.repository }}
        uses: actions/upload-artifact@v4
        with:
          name: trivy-results-sarif
          path: trivy-results.sarif

  # Deployment (Phase 08) - only on develop branch push
  deploy-staging:
    name: Deploy to Staging (Phase 08 - Transition)
    runs-on: ubuntu-latest
    needs:
      [
        code-quality,
        unit-tests,
        integration-tests,
        acceptance-tests,
        security-scan,
      ]
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    # Environment metadata omitted until deployment credentials configured

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Build application
        run: |
          echo "ðŸ—ï¸ Building application..."
          npm ci
          npm run build

      - name: Deploy to staging
        run: |
          echo "ðŸš€ Deploying to staging environment..."
          # Add your deployment commands here
          # e.g., aws, gcloud, kubectl, etc.

      - name: Run smoke tests
        run: |
          echo "ðŸ’¨ Running smoke tests..."
          npm run test:smoke -- --env=staging

      - name: Notify deployment
        if: always()
        run: |
          echo "ðŸ“¢ Deployment to staging: ${{ job.status }}"
          # Add notification logic (Slack, email, etc.)

  # Standards Compliance Report
  compliance-report:
    needs:
      [
        spec-validation,
        code-quality,
        cxx-implementation,
        unit-tests,
        integration-tests,
        requirements-traceability,
        acceptance-tests,
        architecture-validation,
        security-scan,
      ]
    name: Generate Standards Compliance Report
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4

      - name: Generate compliance report
        run: |
          echo "ðŸ“‹ Generating standards compliance report..."

          cat > compliance-report.md << 'EOF'
          # Standards Compliance Report

          **Generated**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
          **Branch**: ${{ github.ref_name }}
          **Commit**: ${{ github.sha }}

          ## ISO/IEC/IEEE 12207:2017 - Software Life Cycle Processes

          - [x] Phase 01: Stakeholder Requirements Definition
          - [x] Phase 02: Requirements Analysis
          - [x] Phase 03: Architecture Design
          - [x] Phase 04: Detailed Design
          - [x] Phase 05: Implementation (TDD)
          - [x] Phase 06: Integration (CI)
          - [x] Phase 07: Verification & Validation
          - [ ] Phase 08: Transition (manual)
          - [ ] Phase 09: Operation & Maintenance (manual)

          ## ISO/IEC/IEEE 29148:2018 - Requirements Engineering

          - âœ… Requirements traceability: ${{ needs['requirements-traceability'].result }}
          - âœ… Stakeholder requirements documented
          - âœ… System requirements specified
          - âœ… Acceptance criteria defined

          ## IEEE 1016-2009 - Software Design Descriptions

          - âœ… Architecture documented
          - âœ… Design decisions recorded (ADRs)
          - âœ… Component designs specified

          ## ISO/IEC/IEEE 42010:2011 - Architecture Description

          - âœ… Architecture validation: ${{ needs['architecture-validation'].result }}
          - âœ… Stakeholder concerns addressed
          - âœ… Architecture viewpoints defined
          - âœ… Architecture views documented

          ## IEEE 1012-2016 - Verification and Validation

          - âœ… Unit tests: ${{ needs['unit-tests'].result }}
          - âœ… Integration tests: ${{ needs['integration-tests'].result }}
          - âœ… Acceptance tests: ${{ needs['acceptance-tests'].result }}
          - âœ… Test coverage: >=${{ env.MIN_TEST_COVERAGE }}%

          ## XP Practices Compliance

          - âœ… Test-Driven Development: Tests run before merge
          - âœ… Continuous Integration: Multiple integrations per day
          - âœ… Coding Standards: Enforced via linting
          - âœ… Simple Design: Complexity <${{ env.MAX_CYCLOMATIC_COMPLEXITY }}
          - âš ï¸ Pair Programming: Manual (not automated)
          - âš ï¸ Collective Ownership: Manual (code reviews)
          - âœ… Refactoring: Continuous (with tests)

          ## Quality Metrics

          | Metric | Target | Status |
          |--------|--------|--------|
          | JS/TS Test Coverage | â‰¥80% | ${{ needs['unit-tests'].result == 'success' && 'âœ…' || 'âŒ' }} |
          | C++ Build & Tests | PASS | ${{ needs['cxx-implementation'].result == 'success' && 'âœ…' || 'âŒ' }} |
          | Cyclomatic Complexity | â‰¤10 | ${{ needs['code-quality'].result == 'success' && 'âœ…' || 'âŒ' }} |
          | Linting | 0 errors | ${{ needs['code-quality'].result == 'success' && 'âœ…' || 'âŒ' }} |
          | Security Vulnerabilities | 0 high/critical | ${{ needs['security-scan'].result == 'success' && 'âœ…' || 'âš ï¸' }} |
          | Requirements Traceability | 100% | ${{ needs['requirements-traceability'].result == 'success' && 'âœ…' || 'âŒ' }} |

          ## Overall Status

          - Code Quality: ${{ needs['code-quality'].result }}
          - Unit Tests: ${{ needs['unit-tests'].result }}
          - C++ Implementation Tests: ${{ needs['cxx-implementation'].result }}
          - Integration Tests: ${{ needs['integration-tests'].result }}
          - Acceptance Tests: ${{ needs['acceptance-tests'].result }}
          - Architecture: ${{ needs['architecture-validation'].result }}
          - Security: ${{ needs['security-scan'].result }}
          - Traceability: ${{ needs['requirements-traceability'].result }}

          **Build Status**: ${{ needs['code-quality'].result == 'success' && needs['unit-tests'].result == 'success' && needs['integration-tests'].result == 'success' && needs['acceptance-tests'].result == 'success' && 'âœ… PASSED' || 'âŒ FAILED' }}
          EOF

          cat compliance-report.md

      - name: Upload compliance report
        uses: actions/upload-artifact@v4
        with:
          name: compliance-report
          path: compliance-report.md

      - name: Comment PR with report
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('compliance-report.md', 'utf8');

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
